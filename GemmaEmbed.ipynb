{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T18:20:52.316698Z","iopub.status.busy":"2024-03-03T18:20:52.316220Z","iopub.status.idle":"2024-03-03T18:20:52.321669Z","shell.execute_reply":"2024-03-03T18:20:52.320740Z","shell.execute_reply.started":"2024-03-03T18:20:52.316662Z"},"trusted":true},"outputs":[],"source":["add_special_tokens = False\n","max_length = 1024\n","debug = False"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T18:21:34.940150Z","iopub.status.busy":"2024-03-03T18:21:34.939404Z","iopub.status.idle":"2024-03-03T18:23:45.646641Z","shell.execute_reply":"2024-03-03T18:23:45.645847Z","shell.execute_reply.started":"2024-03-03T18:21:34.940113Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"988787c9bc674be4b367d5a857b76e90","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n","\n","MODEL_PATH = \"google/gemma-7b-it\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","model = AutoModel.from_pretrained(\n","    MODEL_PATH,\n","    device_map = \"auto\",\n","    trust_remote_code = True,\n","#     torch_dtype=torch.float16,\n","    # quantization_config=quantization_config,\n",")\n","\n","# model = model.to_bettertransformer()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T18:26:16.058163Z","iopub.status.busy":"2024-03-03T18:26:16.056817Z","iopub.status.idle":"2024-03-03T18:26:16.302652Z","shell.execute_reply":"2024-03-03T18:26:16.301744Z","shell.execute_reply.started":"2024-03-03T18:26:16.058107Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/home/zhenlan/Desktop/Projects/LLM Prompt Recovery/Data/nbroad-v1.csv')\n","prompts_txt = list(train.rewrite_prompt.unique())\n","prompts = tokenizer.batch_encode_plus(prompts_txt,add_special_tokens=add_special_tokens,return_attention_mask=False)['input_ids']\n","n_prompt = len(prompts)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T18:27:23.641731Z","iopub.status.busy":"2024-03-03T18:27:23.641342Z","iopub.status.idle":"2024-03-03T18:27:23.648039Z","shell.execute_reply":"2024-03-03T18:27:23.647083Z","shell.execute_reply.started":"2024-03-03T18:27:23.641703Z"},"trusted":true},"outputs":[],"source":["def batch_generator(token_ids, batch_size, pad_token_id):\n","    for i in range(0, len(token_ids), batch_size):\n","        input_ids = token_ids[i:i+batch_size]\n","        lengths = [len(input_id) for input_id in input_ids]\n","        max_len = max(lengths)\n","        input_ids_padded = np.array([np.pad(input_id, (0, max_len - len(input_id)), \\\n","                                            constant_values=pad_token_id) for input_id in input_ids])\n","        yield input_ids_padded, lengths"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["out = []\n","for input_ids, lengths in batch_generator(prompts,4,tokenizer.pad_token_id):\n","    input_ids = torch.tensor(input_ids).to('cuda')\n","    with torch.no_grad():\n","        hidden_states = model(input_ids=input_ids, output_hidden_states=False,output_attentions=False,use_cache=False).last_hidden_state # (batch_size, sequence_length, hidden_size)\n","        # Prepare indices for gathering the last non-padded hidden states\n","        # Subtract 1 from lengths to get the indices of the last tokens\n","        last_token_indices = torch.tensor(lengths).to('cuda') - 1  # (batch_size,)\n","        # Expand dimensions to use for gather\n","        last_token_indices = last_token_indices.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, hidden_states.size(-1))\n","        # Gather the last non-padded hidden states\n","        last_hidden_states = torch.gather(hidden_states, 1, last_token_indices).squeeze(1)\n","    out.append(last_hidden_states.cpu().numpy())"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["out = np.concatenate(out,0).astype(np.float64)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["np.save('../Data/prompt109.npy', out)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(109, 3072)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7806901,"sourceId":67121,"sourceType":"competition"},{"datasetId":4506214,"sourceId":7715833,"sourceType":"datasetVersion"},{"datasetId":4526639,"sourceId":7743982,"sourceType":"datasetVersion"},{"datasetId":4526918,"sourceId":7744338,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
